import{_ as l,c as e,a2 as a,o as i}from"./chunks/framework.BLTIpkzl.js";const c=JSON.parse('{"title":"AI 知识库介绍","description":"","frontmatter":{"outline":"deep"},"headers":[],"relativePath":"knowledgeBase/knowledgeBase-intro.md","filePath":"knowledgeBase/knowledgeBase-intro.md"}'),d={name:"knowledgeBase/knowledgeBase-intro.md"};function o(r,t,n,s,u,h){return i(),e("div",null,t[0]||(t[0]=[a('<h1 id="ai-知识库介绍" tabindex="-1">AI 知识库介绍 <a class="header-anchor" href="#ai-知识库介绍" aria-label="Permalink to &quot;AI 知识库介绍&quot;">​</a></h1><h2 id="什么是-ai知识库" tabindex="-1">什么是 AI知识库？ <a class="header-anchor" href="#什么是-ai知识库" aria-label="Permalink to &quot;什么是 AI知识库？&quot;">​</a></h2><p>简单来说就是将 <code>已有数据</code> 喂给AI大模型，形成一个专属的小仓库。在使用大语言模型（如：chatGPT）时，会从AI知识库中获取数据进行回复。</p><p>举个栗子，当我在与大语言模型进行对话时，如果询问【我在2025年一月一日做了什么？】，这种私人的问题AI是无法精准回复的。</p><p>如果我创建了一个专属的日记知识库，在询问同样问题时，AI就可以从这个知识库中找到答案，而不是凭空想象的回复。</p><h2 id="ai知识库需要用到哪些模型" tabindex="-1">AI知识库需要用到哪些模型 <a class="header-anchor" href="#ai知识库需要用到哪些模型" aria-label="Permalink to &quot;AI知识库需要用到哪些模型&quot;">​</a></h2><ul><li>大语言模型：用以提问与回答 <ul><li>deepseek-ai/DeepSeek-V3</li><li>deepseek-ai/DeepSeek-R1</li><li>openai/GPT-4.1</li></ul></li><li>嵌入模型：用以将文本转化为向量（也就是实现了将数据喂给模型） <ul><li>BAA/bge-m3</li></ul></li></ul><h2 id="详细分步" tabindex="-1">详细分步 <a class="header-anchor" href="#详细分步" aria-label="Permalink to &quot;详细分步&quot;">​</a></h2><h3 id="一、上传文件画面" tabindex="-1">一、上传文件画面 <a class="header-anchor" href="#一、上传文件画面" aria-label="Permalink to &quot;一、上传文件画面&quot;">​</a></h3><p>1.前端：</p><ul><li>上传文件 UI</li><li>显示上传进度和上传成功/失败</li></ul><p>2.后端接口：</p><ul><li>接收上传的文件</li><li>存储源文件（保留原文件方便溯源）</li></ul><p>3.文件解析与分段：</p><ul><li>解析 PDF、Word、txt（推荐用 <code>pdfplumber</code>、<code>python-docx</code>、<code>markdown</code> 库）</li><li>文本分段（按 token 数或段落，推荐 256 ~ 1024 tokens）</li></ul><p>4.文本向量化</p><ul><li>调用 BGE-M3 模型，将分段文本编码成向量</li><li>催出每个分段的： <ul><li>原文</li><li>向量值</li><li>所属文件名、段落编号、上传时间等元数据</li></ul></li></ul><p>5.入库：</p><ul><li>存入向量数据库（Milvus / Chroma / Faiss / PGVector）</li><li>同时存一份 metadata （如：MongoDB / MySQL / Elasticsearch）</li></ul><h3 id="二、对话画面" tabindex="-1">二、对话画面 <a class="header-anchor" href="#二、对话画面" aria-label="Permalink to &quot;二、对话画面&quot;">​</a></h3><p>1.前端：</p><ul><li>聊天UI（输入问题 + 显示AI回复）</li><li>聊天记录展示（可存储历史记录）</li></ul><p>2.后端：</p><ul><li>接收用户问题</li><li>用 BGE-M3 编码成向量</li><li>在向量库中查找最近的 N 个相关文本段</li></ul><p>3.上下文拼接</p><ul><li>把检索出来的文本段，按顺序拼接成上下文 prompt</li><li>加上用户问题，形成大预言模型的输入 prompt</li></ul><p>4.调用大预言模型 API</p><ul><li>调用 API 生成回答</li><li>返回前端</li></ul><p>5.保存聊天记录（可选）</p><ul><li>存储提问、AI回答、上下文段落、时间戳等，方便日志和二次训练</li></ul><h3 id="三、后台知识库管理" tabindex="-1">三、后台知识库管理 <a class="header-anchor" href="#三、后台知识库管理" aria-label="Permalink to &quot;三、后台知识库管理&quot;">​</a></h3><ul><li>查看已上传文件列表</li><li>查看向量入库情况</li><li>删除/更新已上传文件</li><li>查看文档来源、检索命中日志、聊天记录</li></ul><h2 id="涉及模块" tabindex="-1">涉及模块 <a class="header-anchor" href="#涉及模块" aria-label="Permalink to &quot;涉及模块&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">模块</th><th style="text-align:left;">推荐方案</th></tr></thead><tbody><tr><td style="text-align:left;">文档解析</td><td style="text-align:left;">pdfplumber、python-docx、markdown</td></tr><tr><td style="text-align:left;">文本切分</td><td style="text-align:left;">tiktoken、nltk、langchain.textsplitter</td></tr><tr><td style="text-align:left;">向量化</td><td style="text-align:left;">BGE-M3 + FlagEmbedding</td></tr><tr><td style="text-align:left;">向量库</td><td style="text-align:left;">Chroma、Milvus、Faiss、PGVector</td></tr><tr><td style="text-align:left;">大语言模型</td><td style="text-align:left;">OpenAI GPT-4 API、本地 LLaMA</td></tr><tr><td style="text-align:left;">后端</td><td style="text-align:left;">Spring Boot、Node.js、Python Flask</td></tr><tr><td style="text-align:left;">前端</td><td style="text-align:left;">Vue、React、Element UI、Ant Design</td></tr><tr><td style="text-align:left;">文件存储</td><td style="text-align:left;">MinIO、FastDFS、本地路径</td></tr></tbody></table>',34)]))}const f=l(d,[["render",o]]);export{c as __pageData,f as default};
